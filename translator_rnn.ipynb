{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nivanov/miniconda3/envs/dlmetal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import spacy\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from spacy.language import Language\n",
    "from typing import List, Dict, Union, Tuple, Optional\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train a neural translation model based on an encoder-decoder LSTM architecture with attention.\n",
    "The model is trained on the `Multi30k` German to Englsih translations dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # for Apple chips\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', \"'re\", 'gon', 'na', 'go', 'swimming']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"We're gonna go swimming\"\n",
    "\n",
    "[token.text for token in en_nlp.tokenizer(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29000/29000 [00:01<00:00, 16602.83 examples/s]\n",
      "Map: 100%|██████████| 1014/1014 [00:00<00:00, 16363.58 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 16885.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_example(example: Dict[str, str],\n",
    "                     en_nlp: Language,\n",
    "                     de_nlp: Language,\n",
    "                     max_length: int,\n",
    "                     lower: bool,\n",
    "                     eos_token: str):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "\n",
    "    en_tokens = en_tokens + [eos_token]\n",
    "    de_tokens = de_tokens + [eos_token]\n",
    "\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
    "\n",
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<BOS>\"\n",
    "eos_token = \"<EOS>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build our own `Language` object that will adapt to a text corpus and store vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language:\n",
    "    def __init__(self, name: str = None, min_count: int = 2):\n",
    "        self.name = name\n",
    "        self._min_count = min_count\n",
    "        \n",
    "        self.index_to_word = {0: \"<BOS>\", 1: \"<PAD>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word_counts = Counter(self.index_to_word.values())\n",
    "        \n",
    "        self._last_index = list(self.index_to_word.keys())[-1]  # 3\n",
    "        self._max_seq_length = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Language({self.name})\"\n",
    "\n",
    "    @property\n",
    "    def max_seq_length(self) -> int:\n",
    "        return self._max_seq_length\n",
    "\n",
    "    @property\n",
    "    def word_to_index(self) -> Dict[str, int]:\n",
    "        return {word: index for index, word in self.index_to_word.items()}\n",
    "    \n",
    "    @property\n",
    "    def words(self) -> List[str]:\n",
    "        return list(self.index_to_word.values())\n",
    "    \n",
    "    @property\n",
    "    def num_words(self) -> int:\n",
    "        return len(self.words)\n",
    "    \n",
    "    def get_word(self, idx: int) -> str:\n",
    "        return self.index_to_word.get(idx, \"<UNK>\")\n",
    "    \n",
    "    def get_idx(self, word: str) -> int:\n",
    "        return self.word_to_index.get(word, self.word_to_index[\"<UNK>\"])\n",
    "    \n",
    "    def string(self, idxs: Union[List[int], Tensor]) -> str:\n",
    "        if isinstance(idxs, Tensor):\n",
    "            idxs = idxs.cpu().detach().numpy().squeeze()\n",
    "        \n",
    "        return \" \".join([self.get_word(idx) for idx in idxs])\n",
    "    \n",
    "    def indices(self, sentence: Union[str, List[str]]) -> List[int]:\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.split()\n",
    "        \n",
    "        return [self.get_idx(word) for word in sentence]\n",
    "    \n",
    "    def add_word(self, word: str) -> None:\n",
    "        if word not in self.words:\n",
    "            self.word_counts.update([word])\n",
    "\n",
    "            if self.word_counts[word] > self._min_count:\n",
    "                # only update frequent words\n",
    "                self.index_to_word[self._last_index + 1] = word\n",
    "                self._last_index += 1\n",
    "    \n",
    "    def add_sentence(self, sentence: List[str]) -> None:\n",
    "        seq_length = len(sentence)\n",
    "        if seq_length > self._max_seq_length:\n",
    "            self._max_seq_length = seq_length\n",
    "        \n",
    "        for word in sentence:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max seq length src: 45\n",
      "Max seq length tgt: 42\n"
     ]
    }
   ],
   "source": [
    "min_word_counts = 2\n",
    "tgt_lang = Language(\"English\", min_count=min_word_counts)\n",
    "src_lang = Language(\"German\", min_count=min_word_counts)\n",
    "\n",
    "NUM_EXAMPLES = train_data.num_rows\n",
    "\n",
    "# build vocabs\n",
    "for example in train_data.take(NUM_EXAMPLES):\n",
    "    src_lang.add_sentence(example[\"de_tokens\"])\n",
    "    tgt_lang.add_sentence(example[\"en_tokens\"])\n",
    "\n",
    "print(f\"Max seq length src: {src_lang.max_seq_length}\")\n",
    "print(f\"Max seq length tgt: {tgt_lang.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size src: 5374\n",
      "Vocab size tgt: 4556\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size src: {src_lang.num_words}\")\n",
    "print(f\"Vocab size tgt: {tgt_lang.num_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def numericalize_example(example, tgt_lang: Language, src_lang: Language):\n",
    "#     en_ids = tgt_lang.indices(example[\"en_tokens\"])\n",
    "#     de_ids = src_lang.indices(example[\"de_tokens\"])\n",
    "#     return {\"en_ids\": en_ids, \"de_ids\": de_ids}\n",
    "\n",
    "# fn_kwargs = {\"tgt_lang\": tgt_lang, \"src_lang\": src_lang}\n",
    "\n",
    "# train_data = train_data.take(NUM_EXAMPLES).map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "# valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "# test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "\n",
    "# train_data.save_to_disk(\"train_data_de_en.dataset\")\n",
    "# valid_data.save_to_disk(\"valid_data_de_en.dataset\")\n",
    "# test_data.save_to_disk(\"test_data_de_en.dataset\")\n",
    "\n",
    "# either load from disk or uncomment code above and run\n",
    "train_data = datasets.load_from_disk(f\"datasets/train_data_de_en.dataset\")\n",
    "valid_data = datasets.load_from_disk(f\"datasets/valid_data_de_en.dataset\")\n",
    "test_data = datasets.load_from_disk(f\"datasets/test_data_de_en.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ein kleines mädchen klettert in ein <UNK> aus holz . <EOS>\n",
      "a little girl climbing into a wooden playhouse . <EOS>\n"
     ]
    }
   ],
   "source": [
    "print(src_lang.string(train_data[2][\"de_ids\"]))\n",
    "print(tgt_lang.string(train_data[2][\"en_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn\n",
    "\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False, pin_memory=True):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data,\n",
    "                                    batch_size,\n",
    "                                    tgt_lang.word_to_index[\"<PAD>\"],\n",
    "                                    shuffle=True)\n",
    "\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, tgt_lang.word_to_index[\"<PAD>\"])\n",
    "test_data_loader = get_data_loader(test_data, batch_size, tgt_lang.word_to_index[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 src_vocab_size: int,\n",
    "                 num_layers: int = 1,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self._num_layers = num_layers\n",
    "        self._hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, bidirectional=False, num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            input of size (batch_size, src_seq_length)\n",
    "        Outputs\n",
    "            output of size (batch_size, src_seq_length, hidden_dim * 1)\n",
    "            hidden of size (batch_size, 1, (hidden_dim * 1))\n",
    "            cell of size (batch_size, 1, (hidden_dim * 1))\n",
    "        \"\"\"\n",
    "        # x.shape (batch_size, seq_length, embed_dim)\n",
    "        x = self.embedding(input)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # LSTM expects batch as second dimension\n",
    "        # x.shape (seq_length, batch_size, embed_dim)\n",
    "        x = x.transpose(1, 0)\n",
    "\n",
    "        # output.shape (seq_length, batch_size, hidden_dim * 1)\n",
    "        # hidden.shape (num_layers, batch_size, hidden_dim) [2 * num_layers if bi-directional LSTM]\n",
    "        # cell.shape (num_layers, batch_size, hidden_dim) [2 * num_layers if bi-directional LSTM]\n",
    "        output, (hidden, cell) = self.rnn(x)\n",
    "        \n",
    "        # output.shape (batch_size, seq_length, hidden_dim * 1)\n",
    "        output = output.transpose(1, 0)\n",
    "\n",
    "        # hidden.shape (num_layers, batch_size, hidden_dim * 1)\n",
    "        # hidden = hidden.reshape(self._num_layers, batch_size, self._hidden_dim * 1)\n",
    "\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hidden_dim: int, dec_hidden_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        assert enc_hidden_dim == dec_hidden_dim, \"Encoder and decoder must have the same hidden dim\"\n",
    "\n",
    "        self.fc_1 = nn.Linear(in_features=enc_hidden_dim + dec_hidden_dim, out_features=dec_hidden_dim)\n",
    "        self.fc_2 = nn.Linear(in_features=dec_hidden_dim, out_features=1, bias=False)\n",
    "    \n",
    "    def forward(self, hidden: Tensor, encoder_outputs: Tensor):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            hidden: (num_layers, batch_size, dec_hidden_dim) [query]\n",
    "            encoder_ouputs: (batch_size, seq_length, enc_hidden_dim) [keys, values]\n",
    "        Outputs\n",
    "            weighted attention (batch_size, 1, dec_hidden_dim)\n",
    "        \"\"\"\n",
    "        seq_lenght = encoder_outputs.size(1)\n",
    "\n",
    "        # hidden.shape (batch_size, num_layers, dec_hidden_dim)\n",
    "        hidden = hidden.transpose(1, 0)\n",
    "        # hidden.shape (batch_size, 1, dec_hidden_dim)\n",
    "        hidden = hidden.sum(axis=1).unsqueeze(1)\n",
    "        # hidden.shape (batch_size, seq_lenght, dec_hidden_dim)\n",
    "        hidden = hidden.repeat(1, seq_lenght, 1)\n",
    "\n",
    "        # input.shape (batch_size, seq_lenght, dec_hidden_dim + enc_hidden_dim)\n",
    "        input = torch.cat([hidden, encoder_outputs], axis=2)\n",
    "\n",
    "        # energy.shape (batch_size, seq_length, dec_hidden_dim)\n",
    "        energy = self.fc_1(input).relu()\n",
    "\n",
    "        # attention.shape (batch_size, seq_length, 1)\n",
    "        attention = self.fc_2(energy)\n",
    "        # attention.shape (batch_size, 1, seq_length)\n",
    "        attention = attention.transpose(2, 1).softmax(axis=2)\n",
    "\n",
    "        # weighted.shape (batch_size, 1, enc_hidden_dim)\n",
    "        weighted = torch.bmm(attention, encoder_outputs)\n",
    "\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 max_seq_legth: int = 50,\n",
    "                 num_layers: int = 1,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_legth = max_seq_legth\n",
    "\n",
    "        self.embedding = nn.Embedding(tgt_vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(input_size=embed_dim + hidden_dim, hidden_size=hidden_dim, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(in_features=hidden_dim, out_features=tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = Attention(enc_hidden_dim=hidden_dim, dec_hidden_dim=hidden_dim)\n",
    "        # self.attention = ScaledDotProductAttention(hidden_dim=hidden_dim, seq_length=50)\n",
    "    \n",
    "    def forward(self,\n",
    "                input: Tensor,\n",
    "                encoder_outputs: Tensor,\n",
    "                encoder_hidden: Tensor,\n",
    "                encoder_cell: Tensor,\n",
    "                tgt: Tensor,\n",
    "                teacher_forcing: float = 0.5) -> Tensor:\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            input (batch_size, 1)\n",
    "            encoder_outputs (batch_size, seq_length, hidden_dim * 1)\n",
    "            encoder_hidden state (num_layers, batch_size, hidden_dim)\n",
    "            encoder_cell state (num_layers, batch_size, hidden_dim)\n",
    "            tgt of shape (batch_size, tgt_seq_length)\n",
    "            teacher_forcing: teacher forcing ratio\n",
    "        Outputs\n",
    "            log-probabilities of shape (batch_size, tgt_seq_length, tgt_vocab_size)\n",
    "        \"\"\"\n",
    "        decoder_outputs = []  # type: List[torch.Tensor]\n",
    "\n",
    "        hidden = encoder_hidden\n",
    "        cell = encoder_cell\n",
    "\n",
    "        # during training we generate same number of words as target length\n",
    "        # during inference (tgt=None) we will generate max_seq_legth words\n",
    "        target_length = tgt.size(1) if tgt is not None else self.max_seq_legth\n",
    "\n",
    "        for t in range(target_length):\n",
    "            # decoder_output.shape (1, batch_size, tgt_vocab_size)\n",
    "            # hidden.shape (num_layers, batch_size, hidden_dim)\n",
    "            # cell.shape (num_layers, batch_size, hidden_dim)\n",
    "            decoder_output, hidden, cell = self._one_forward_step(input, encoder_outputs, hidden, cell)\n",
    "            \n",
    "            # will be shape (tgt_seq_length, 1, batch_size, tgt_vocab_size)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            # teacher forcing\n",
    "            if (tgt is not None) and (np.random.uniform() < teacher_forcing):\n",
    "                # decoder_input.shape (batch_size, 1)\n",
    "                input = tgt[:, t].unsqueeze(1)\n",
    "            else:\n",
    "                # use decoder's own predictions\n",
    "                # pred.shape (batch_size, 1, tgt_vocab_size)\n",
    "                pred = decoder_output.log_softmax(dim=-1).transpose(1, 0)\n",
    "                _, input = pred.max(dim=-1)\n",
    "                # _, pred_top2 = pred.topk(2, axis=-1)\n",
    "                \n",
    "             \n",
    "        \n",
    "        # decoder_outputs.shape (tgt_seq_length, 1, batch_size, hidden_dim)\n",
    "        decoder_outputs = torch.stack(decoder_outputs, dim=0)\n",
    "        # decoder_outputs.shape (tgt_seq_length, batch_size, hidden_dim)\n",
    "        decoder_outputs = decoder_outputs.squeeze(1)\n",
    "\n",
    "        # decoder_outputs.shape (batch_size, tgt_seq_length, hidden_dim)\n",
    "        decoder_outputs = decoder_outputs.transpose(1, 0)\n",
    "\n",
    "        # decoder_outputs.shape (batch_size, tgt_seq_length, tgt_vocab_size)\n",
    "        # decoder_outputs = self.fc(decoder_outputs)\n",
    "\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "\n",
    "        return decoder_outputs\n",
    "\n",
    "    def _one_forward_step(self,\n",
    "                          input: Tensor,\n",
    "                          encoder_outputs: Tensor,\n",
    "                          hidden: Tensor,\n",
    "                          cell: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        # input.shape (batch_size, 1, embed_dim)\n",
    "        input = self.dropout(self.embedding(input))\n",
    "        \n",
    "        # attn_vector.shape (batch_size, 1, hidden_dim)\n",
    "        attn_vector = self.attention(hidden, encoder_outputs)\n",
    "\n",
    "        # decoder_rnn_input.shape (batch_size, 1, embed_dim + hidden_dim)\n",
    "        decoder_rnn_input = torch.cat([input, attn_vector], dim=-1)\n",
    "        # decoder_rnn_input.shape (1, batch_size, embed_dim + hidden_dim)\n",
    "        decoder_rnn_input = decoder_rnn_input.transpose(1, 0)\n",
    "\n",
    "        decoder_rnn_input = F.relu(decoder_rnn_input)\n",
    "\n",
    "        # decoder_output.shape (1, batch_size, hidden_dim)\n",
    "        # hidden.shape (num_layers, batch_size, hidden_dim)\n",
    "        # cell.shape (num_layers, batch_size, hidden_dim)\n",
    "        decoder_output, (hidden, cell) = self.rnn.forward(decoder_rnn_input, (hidden, cell))\n",
    "        \n",
    "        # decoder_output.shape (1, batch_size, tgt_vocat_size)\n",
    "        decoder_output = self.fc(decoder_output)\n",
    "\n",
    "        return decoder_output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslatorModel(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, start_token: Tensor, src: Tensor, tgt: Tensor):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            start_token (batch_size, 1)\n",
    "            src (batch_size, src_seq_length)\n",
    "            tgt (batch_size, tgt_seq_length)\n",
    "        Outputs\n",
    "            log-probabilities of shape (batch_size, tgt_seq_length, tgt_vocab_size)\n",
    "        \"\"\"\n",
    "        encoder_outputs, encoder_hidden, encoder_cell = self.encoder(src)\n",
    "        decoder_outputs = self.decoder(start_token, encoder_outputs, encoder_hidden, encoder_cell, tgt)\n",
    "        return decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model num parameters: 9,607,116\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"bias\" in name:\n",
    "            nn.init.zeros_(param.data)\n",
    "        else:\n",
    "            nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "loss_function = nn.NLLLoss(ignore_index=tgt_lang.get_idx(\"<PAD>\"))\n",
    "\n",
    "dropout_ratio = 0.5\n",
    "hidden_dim = 512\n",
    "embed_dim = 256\n",
    "num_layers = 1\n",
    "\n",
    "encoder = Encoder(embed_dim=embed_dim,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  src_vocab_size=src_lang.num_words,\n",
    "                  num_layers=num_layers,\n",
    "                  dropout=dropout_ratio).to(device)\n",
    "\n",
    "decoder = Decoder(embed_dim=embed_dim,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  tgt_vocab_size=tgt_lang.num_words,\n",
    "                  max_seq_legth=tgt_lang.max_seq_length + 1,\n",
    "                  num_layers=num_layers,\n",
    "                  dropout=dropout_ratio).to(device)\n",
    "\n",
    "translator = TranslatorModel(encoder, decoder).to(device)\n",
    "\n",
    "translator.apply(init_weights)\n",
    "print(f\"Model num parameters: {count_parameters(translator):,}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(translator.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(model: nn.Module,\n",
    "              loss_function: nn.NLLLoss,\n",
    "              batch: Dict[str, Tensor],\n",
    "              device: torch.device) -> float:\n",
    "    # src.shape (batch_size, seq_length)\n",
    "    src = batch[\"de_ids\"].to(device).transpose(1, 0)  # type: Tensor\n",
    "    tgt = batch[\"en_ids\"].to(device).transpose(1, 0)  # type: Tensor\n",
    "    \n",
    "    start_token = torch.zeros((src.size(0), 1), dtype=torch.long).fill_(tgt_lang.word_to_index[\"<BOS>\"]).to(device)\n",
    "\n",
    "    log_probs = model(start_token, src, tgt)  # type: Tensor\n",
    "    log_probs = log_probs.reshape(-1, log_probs.size(-1))\n",
    "\n",
    "    loss = loss_function(log_probs, tgt.reshape(-1).long())\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train_one_epoch(model: nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    loss_function: nn.NLLLoss,\n",
    "                    data_loader: torch.utils.data.DataLoader,\n",
    "                    device: torch.device) -> float:\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # src = batch[\"de_ids\"].to(device).transpose(1, 0)  # type: torch.Tensor\n",
    "        # tgt = batch[\"en_ids\"].to(device).transpose(1, 0)  # type: torch.Tensor\n",
    "        # start_token = torch.zeros((src.size(0), 1), dtype=torch.long).fill_(tgt_lang.word_to_index[\"<BOS>\"]).to(device)\n",
    "\n",
    "        # outputs = model(start_token, src, tgt)  # type: torch.Tensor\n",
    "\n",
    "        # probabilities = outputs.reshape(-1, outputs.size(-1))\n",
    "\n",
    "        # loss = loss_function(probabilities, tgt.reshape(-1).long())\n",
    "        loss = run_batch(model=model, loss_function=loss_function, batch=batch, device=device)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(translator.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "def translate_from_tensor(model: nn.Module, input: Tensor, tgt_lang: Language, tgt: Optional[Tensor]):\n",
    "    start_token = torch.zeros((1, 1), dtype=torch.long).fill_(tgt_lang.word_to_index[\"<BOS>\"]).to(device)\n",
    "\n",
    "    # outputs.shape (batch_size, tgt_seq_length, tgt_vocab_size)\n",
    "    log_probs = model(start_token, input, tgt=tgt)  # type: Tensor\n",
    "\n",
    "    # pred_top2.shape (batch_size, tgt_seq_length, 2)\n",
    "    _, pred_top2 = log_probs.topk(2, dim=-1)\n",
    "    \n",
    "    # pred_top2.shape (tgt_seq_length, 2)\n",
    "    pred_top2 = pred_top2.squeeze(0)  # because batch_size=1 here\n",
    "\n",
    "    # unpack first 2 top predictions\n",
    "    first_pred, second_pred = pred_top2[:, 0].unsqueeze(1), pred_top2[:, 1].unsqueeze(1)\n",
    "    \n",
    "    # in case first top prediction is UNK use second top prediction\n",
    "    unk_idx = tgt_lang.word_to_index[\"<UNK>\"]\n",
    "    indices = torch.where(first_pred == unk_idx, second_pred, first_pred)\n",
    "    \n",
    "    indices = indices.squeeze().tolist()\n",
    "\n",
    "    sentence = tgt_lang.string(indices)\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def print_sentences(data: datasets.Dataset, idx: int, model: nn.Module, src_lang: Language, tgt_lang: Language, device: torch.device):\n",
    "    data_eval_src = data[idx][\"de_ids\"].to(device)\n",
    "    data_eval_tgt = data[idx][\"en_ids\"].to(device)\n",
    "    sentence_src = src_lang.string(data_eval_src)\n",
    "    sentence_tgt = tgt_lang.string(data_eval_tgt)\n",
    "    sentence_evaluated = translate_from_tensor(model, data_eval_src.unsqueeze(0), tgt_lang, data_eval_tgt.unsqueeze(0))\n",
    "\n",
    "    print(f\"SOURCE: {sentence_src}\")\n",
    "    print(f\"TARGET: {sentence_tgt}\")\n",
    "    print(f\"MODEL: {sentence_evaluated}\")\n",
    "\n",
    "def translate_from_string(sentence: str, model: nn.Module, src_lang: Language, tgt_lang: Language, device: torch.device) -> str:\n",
    "    sentence_idxs = src_lang.indices(sentence)\n",
    "    sentence_idxs = np.array(sentence_idxs)[np.newaxis, :]\n",
    "    sentence_idxs = torch.from_numpy(sentence_idxs).to(device)\n",
    "    translation_raw = translate_from_tensor(model, sentence_idxs, tgt_lang, tgt=None)\n",
    "    translation_trimmed = translation_raw.split(\" <EOS>\")[0]\n",
    "    \n",
    "    return translation_trimmed\n",
    "\n",
    "def evaluate_model(model: nn.Module,\n",
    "                   data_loader: torch.utils.data.DataLoader,\n",
    "                   loss_function: nn.NLLLoss,\n",
    "                   device: torch.device):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(data_loader):\n",
    "            loss = run_batch(model=model, loss_function=loss_function, batch=batch, device=device)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: ein mann geht an einem silbernen fahrzeug vorbei . <EOS>\n",
      "TARGET: a man walks by a silver vehicle . <EOS>\n",
      "MODEL: stand observing scoops people five kettle grins silk fix\n"
     ]
    }
   ],
   "source": [
    "# print untrained model translations\n",
    "print_sentences(data=train_data, idx=42, model=translator, src_lang=src_lang, tgt_lang=tgt_lang, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed with training or jump right to `Evaluate` section to load pre-trained model weights.\n",
    "Training was performed on an Nvidia RTX4090 GPU and took around 6 minutes for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "\n",
    "translator.train()\n",
    "\n",
    "model_name = f\"translator_rnn_{num_layers}_layers\"\n",
    "best_val_loss = float(\"inf\")\n",
    "train_losses, valid_losses = [], []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    time_start = time.time()\n",
    "    epoch_loss = train_one_epoch(translator, optimizer,\n",
    "                                 loss_function, train_data_loader, device)\n",
    "    \n",
    "    time_passed_seconds = time.time() - time_start\n",
    "    \n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    valid_loss = evaluate_model(model=translator, data_loader=valid_data_loader, loss_function=loss_function, device=device)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    if valid_loss < best_val_loss:\n",
    "        # save best validaiton loss model\n",
    "        best_val_loss = valid_loss\n",
    "        print(\"Saving model state...\")\n",
    "        torch.save(translator.state_dict(), f\"{model_name}_bestval.pt\")\n",
    "    \n",
    "    # save model\n",
    "    torch.save(translator.state_dict(), f\"{model_name}.pt\")\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, elapsed: {time_passed_seconds:.0f} sec, train loss: {epoch_loss:.4f}, validation loss: {valid_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        random_eval_idx = int(np.random.choice(list(range(NUM_EXAMPLES))))\n",
    "        print_sentences(data=train_data, idx=random_eval_idx, model=translator, src_lang=src_lang, tgt_lang=tgt_lang, device=device)\n",
    "    \n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, color=\"blue\", label=\"Train\")\n",
    "plt.plot(valid_losses, color=\"red\", label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(\"Average loss per epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/mv0mfx752sb76dmyd9_tr18w0000gn/T/ipykernel_82604/3961460715.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  translator.load_state_dict(torch.load(f\"models/translator_rnn_{num_layers}_layers_bestval.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TranslatorModel(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5374, 256)\n",
       "    (rnn): LSTM(256, 512)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4556, 256)\n",
       "    (rnn): LSTM(768, 512)\n",
       "    (fc): Linear(in_features=512, out_features=4556, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (attention): Attention(\n",
       "      (fc_1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc_2): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.load_state_dict(torch.load(f\"models/translator_rnn_{num_layers}_layers_bestval.pt\", map_location=device))\n",
    "translator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: ein kind vor seinem eigenen spiegelbild , das sich zur kamera dreht und lächelt . <EOS>\n",
      "TARGET: a child in front of his own reflection turning towards the camera and smiling . <EOS>\n",
      "MODEL: a child in front of his reflection reflection , the the camera . smiling . <EOS>\n"
     ]
    }
   ],
   "source": [
    "random_eval_idx = int(np.random.choice(list(range(NUM_EXAMPLES))))\n",
    "print_sentences(data=train_data, idx=random_eval_idx, model=translator, src_lang=src_lang, tgt_lang=tgt_lang, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: ein mann sitzt auf einer <UNK> und arbeitet an einer maschine . <EOS>\n",
      "TARGET: man sitting atop oil rig on machine working . <EOS>\n",
      "MODEL: a sitting on a stoop of a working on a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SOURCE: drei frauen stehen bei einem strand im wasser . <EOS>\n",
      "TARGET: three women standing in the water beside a beach . <EOS>\n",
      "MODEL: three women standing in the water on a beach . <EOS>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SOURCE: das rennauto und der fahrer von <UNK> fahren eine rennstrecke entlang . <EOS>\n",
      "TARGET: the <UNK> racing car and driver driving down a racetrack . <EOS>\n",
      "MODEL: the rally car and and the driver is a racetrack . <EOS>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SOURCE: eine junge blonde frau geht durch eine straße mit einer schwarzen handtasche . <EOS>\n",
      "TARGET: a young blond woman walks through a street with a black purse . <EOS>\n",
      "MODEL: a young blond woman walks through a street with a black purse . <EOS>\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SOURCE: eine gruppe jugendlicher genießt ein schaumbad . <EOS>\n",
      "TARGET: the group of young people are in a bubble bath enjoying themselves . <EOS>\n",
      "MODEL: a group of teens enjoying enjoying a bubble bubble . . <EOS> . <EOS>\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# idxs = [42, 422, 10, 7, 999]\n",
    "idxs = [np.random.randint(low=0, high=NUM_EXAMPLES) for _ in range(5)]\n",
    "\n",
    "for idx in idxs:\n",
    "    print_sentences(data=train_data, idx=idx, model=translator, src_lang=src_lang, tgt_lang=tgt_lang, device=device)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "def get_tokenizer_fn(nlp: Language, lower: bool):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn\n",
    "\n",
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 32.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.3086418885670576,\n",
       " 'precisions': [0.6574118397957556,\n",
       "  0.39413906710594765,\n",
       "  0.25090184165559143,\n",
       "  0.16498846234529055],\n",
       " 'brevity_penalty': 0.9590555442023709,\n",
       " 'length_ratio': 0.9598713432378618,\n",
       " 'translation_length': 12534,\n",
       " 'reference_length': 13058}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute BLEU metric on test data\n",
    "predictions, references = [], []\n",
    "for idx in tqdm(range(test_data.num_rows)):\n",
    "    data_eval_src = test_data[idx][\"de_ids\"].to(device)\n",
    "    sentence_evaluated = translate_from_tensor(translator,\n",
    "                                    data_eval_src.unsqueeze(0),\n",
    "                                    tgt_lang,\n",
    "                                    tgt=None).split(\"<EOS>\")[0]\n",
    "\n",
    "\n",
    "    predictions.append(sentence_evaluated)\n",
    "    references.append(test_data[idx][\"en\"])\n",
    "\n",
    "bleu.compute(predictions=predictions, references=references, tokenizer=tokenizer_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
